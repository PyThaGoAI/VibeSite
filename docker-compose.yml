version: '3'

services:
  localsite-ai:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - HOST=0.0.0.0
      # Choose the default provider (deepseek, openai_compatible, ollama, or lm_studio)
      - DEFAULT_PROVIDER=openai_compatible
      
      # DeepSeek Configuration - REPLACE WITH YOUR ACTUAL OPENROUTER API KEY
      - DEEPSEEK_API_KEY=YOUR_OPENROUTER_API_KEY_HERE
      - DEEPSEEK_API_BASE=https://openrouter.ai/api/v1
      
      # OpenAI Compatible Configuration - REPLACE WITH YOUR ACTUAL OPENROUTER API KEY
      - OPENAI_COMPATIBLE_API_KEY=YOUR_OPENROUTER_API_KEY_HERE
      - OPENAI_COMPATIBLE_API_BASE=https://openrouter.ai/api/v1
    # volumes:
    #   - ./:/app
    extra_hosts:
      # Important: Allows access to the host machine
      - "host.docker.internal:host-gateway"