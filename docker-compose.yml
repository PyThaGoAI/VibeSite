version: '3'

services:
  localsite-ai:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - HOST=0.0.0.0
      # Choose the default provider (deepseek, openai_compatible, ollama, or lm_studio)
      - DEFAULT_PROVIDER=openai_compatible
      
      # DeepSeek Configuration - Uses environment variable from .env.local
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
      - DEEPSEEK_API_BASE=https://openrouter.ai/api/v1
      
      # OpenAI Compatible Configuration - Uses environment variable from .env.local
      - OPENAI_COMPATIBLE_API_KEY=${OPENAI_COMPATIBLE_API_KEY}
      - OPENAI_COMPATIBLE_API_BASE=https://openrouter.ai/api/v1
    env_file:
      - .env.local
    # volumes:
    #   - ./:/app
    extra_hosts:
      # Important: Allows access to the host machine
      - "host.docker.internal:host-gateway"