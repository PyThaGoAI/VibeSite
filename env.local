
##############################
# üîê API Keys & Endpoints
##############################

# üß† DeepSeek
DEEPSEEK_API_KEY=sk-94b62159330b4f74bcd84cc2269e93ce
DEEPSEEK_API_BASE=https://api.deepseek.com

# üß† OpenAI (ChatGPT, GPT-4, GPT-4o, etc)
OPENAI_API_KEY=sk-your-openai-key
OPENAI_API_BASE=https://api.openai.com/v1

# üß† Anthropic (Claude 3.5, 3-opus, etc)
ANTHROPIC_API_KEY=sk-your-anthropic-key
ANTHROPIC_API_BASE=https://api.anthropic.com/v1

# üß† Groq (Mixtral, Gemma, LLaMA via Groq speed)
GROQ_API_KEY=sk-your-groq-key
GROQ_API_BASE=https://api.groq.com/openai/v1

# üß† Together AI (Mixtral, Zephyr, OpenChat, etc)
TOGETHER_API_KEY=sk-your-together-key
TOGETHER_API_BASE=https://api.together.xyz/v1

# üß† Cohere (Command-R+, RAG-ready)
COHERE_API_KEY=sk-your-cohere-key
COHERE_API_BASE=https://api.cohere.ai/v1

# üß† Mistral (OpenWeaver, Mixtral, Codestral, etc)
MISTRAL_API_KEY=sk-your-mistral-key
MISTRAL_API_BASE=https://api.mistral.ai/v1

# üß† Google Gemini (Pro 1.5 via PaLM API)
GEMINI_API_KEY=sk-your-google-api-key
GEMINI_API_BASE=https://generativelanguage.googleapis.com/v1beta

# üß† Lamini (Fine-tuning enterprise LLMs)
LAMINI_API_KEY=sk-your-lamini-key
LAMINI_API_BASE=https://api.lamini.ai/v1

# üß† OpenRouter (unified LLM API)
OPENROUTER_API_KEY=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
OPENROUTER_API_BASE=https://openrouter.ai/api/v1

##############################
# üñ•Ô∏è Local Models & Dev Tools
##############################

# üêè Ollama (local LLMs like llama3, phi3, etc)
OLLAMA_API_BASE=http://localhost:11434

# üß™ LM Studio
LM_STUDIO_API_BASE=http://localhost:1234/v1

# üß† Custom LLMs or Internal APIs
CUSTOM_LLM_API_KEY=sk-your-custom-key
CUSTOM_LLM_API_BASE=http://localhost:5000/v1

##############################
# ‚öôÔ∏è General Settings
##############################

# Default LLM Provider: openai | deepseek | anthropic | groq | together | ollama | lm_studio | mistral | cohere | gemini | lamini
DEFAULT_PROVIDER=openrouter

# Default Model for selected provider (e.g., gpt-4o, claude-3-opus, mixtral-8x7b, llama3:8b, command-r+, mistral-small, gemini-1.5-pro)
DEFAULT_MODEL=gpt-4o

# Enable logging, debugging, cache control
DEBUG=true
CACHE_MODE=memory

# API Retry & Timeout settings
API_TIMEOUT_SECONDS=60
API_MAX_RETRIES=3

# Locale / Language / Region settings
DEFAULT_LANG=ro
DEFAULT_REGION=EU

# RAG / Embedding Config
EMBEDDING_MODEL=text-embedding-3-large
VECTOR_DB_PROVIDER=weaviate

# File upload / max size (if used)
MAX_UPLOAD_MB=50

##############################
# ‚úÖ Status
##############################
# This .env is built for premium LLM routing & orchestration ‚Äì June 2025 version
# Make sure your orchestrator/app reads DEFAULT_PROVIDER and DEFAULT_MODEL at runtime
